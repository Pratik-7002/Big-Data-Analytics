# Big-Data-Analytics
The Project is about building a prediction model. Task includes Python, AWS, Hive, Hadoop, RapidMiner

The project involves utilizing Big Data Analytics, specifically with a focus on Deep Learning methodologies. 
The process includes creating and handling tables in Hive utilizing an AWS Hadoop Cluster, managing and uploading large datasets, and executing data randomization and retrieval.
Key tasks include data preprocessing such as identifying null columns, removing unnecessary columns, replacing categorical variables, and merging data sets. 
The project also involves detailed data visualization through heatmaps to understand feature correlations and implementing deep learning for predictive modeling. 
The methodology adopted streamlines data retrieval, attribute selection, model training, and evaluation, focusing on accuracy, precision, and recall to enhance the decision-making process. 
The final phase involves making predictions on the merged dataset, selecting the most suitable model for testing based on performance metrics.
